\section{Linear Function Approximation with (Weighted) Mean Squared Error}

In this scheme, we'll have \(p^\star(s)\), a stationary distribution over states that assigns a weight to each state. Note that we use it instead of uniform weighting, i.e., \(\frac{1}{|S|}\), as some states may be visited less frequently or not at all by the agent. Then, we define the weighted mean squared error (MSE) as:\[
e_{\text{MS}}(\mathbf{w}) 
= \mathbb{E}_{s \sim p^\star(s)}\left[\left(v_\pi(s) - \hat{v}(s;\mathbf{w})\right)^2\right].\]
In discrete state spaces, we can write it down as:
\[
e_{\text{MS}}(\mathbf{w})
\;=\; \sum_{s \in \mathcal{S}} p^\star(s)\,\bigl(v_\pi(s) - \hat{v}(s;\mathbf{w})\bigr)^2.
\]
\[
e_{\text{MS}}(\mathbf{w})
\;=\; \sum_{s \in \mathcal{S}} p^\star(s)\,\bigl(v_\pi(s) - \mathbf{w}^\top \mathbf{f}(s)\bigr)^2.
\]
In matrix form:
\[
e_{\text{MS}}(\mathbf{w}) 
\;=\; (\mathbf{v}_\pi - F\,\mathbf{w})^\top D_{p^\star} \,(\mathbf{v}_\pi - F\,\mathbf{w}),
\]
where \(D_{p^\star}\) is a diagonal matrix with \(D_{p^\star}(s,s) = p^\star(s)\). Minimizing this MSE w.r.t \(\mathbf{w}\) yields
\[
\nabla_{\mathbf{w}}\, e_{\text{MS}}(\mathbf{w}) \;=\; \mathbf{0}
\;\;\;\Rightarrow\;\;\;
\mathbf{w}^*
\;=\; (F^\top\,D\,F)^{-1}\,F^\top\,D\,\mathbf{v}_\pi,
\]
if \((F^\top D F)\) is invertible.
